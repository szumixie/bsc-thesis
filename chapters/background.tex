\chapter{Background}\label{ch:background}

\section{Functional programming}\label{sec:functional}

\emph{Functional programming} is the idea of structuring software by composing
and applying functions, where mutable state and side effects are isolated and
kept track of. The functions are similar to mathematical functions, they take in
values as parameters and return new values based on the given arguments. In
contrast to imperative procedues, which are defined by sequences of statements
with side effects, function definitions are expression trees of functions,
operators, and values~\cite{functional-Hudak, functional-Hughes}.

Functions are treated just like any other values in functional languages, they
can be given in function arguments, returned from functions, stored in data
structures, and defined in any context~\cite{functional-Hudak, sicp}.

If one defines a function that takes other functions as arguments, it is known
as a \emph{higher-order functions}. For example,
\begin{equation}
  \mathit{twice}(f, x) := f(f(x))
  \label{eq:higher-order-ex}
\end{equation}
is a higher order function, it takes a function and a value, returns a function
applied to that value twice~\cite{functional-Hudak}. Higher-order functions
allow one to refactor functions with similar structures by having parts of the
definition be parameters of the new function.

The ability for a function to return another function gives rise to the
technique known as \emph{currying}, where instead of having function arguments
be given in tuples of values, the function is instead defined to have a single
argument then directly return another function that takes another argument and
so on~\cite{functional-Hudak, functional-Barendregt, combinator-Curry}. For
example,
\begin{equation}
  (f(x))(y)
  \label{eq:curry-ex}
\end{equation}
is a curried function applied to two arguments.

A desirable trait in functional programming is \emph{referential transparency}.
It allows one to replace any variable with its definition or factor out parts of
the expressions into a new variable without changing the semantics of the
program~\cite{functional-Hudak, functional-Hughes, functional-Barendregt}. This
property is lost if side effects are unrestricted in functions.

Imperative loops need mutable variables to function, so to avoid mutable state,
recursion is used instead in functional programming~\cite{functional-Hudak}.
Often higher-order combinators which use recursion under the hood are used
instead of explicit recursion, such as maps, folds, and recursion schemes, using
them one can be sure that a particular function terminates~\cite{fold-Hutton,
  bananas-Meijer}. With an optimizing compiler, recursive functions can be just as
performant as imperative loops~\cite{sicp}.

\section{Lambda calculus}\label{sec:lambda}

\emph{Lambda calculus} is a model of computation based on mathematical
functions, it is the basis of functional programming
languages~\cite{functional-Hudak}. The simplest untyped version only has three
syntactic constructs (see \cref{fig:lambda-syntax}) with parentheses for
grouping. Lambda abstraction binds or captures variables and creates anonymous
functions, those variables are \emph{bound}, variables which are not bound with
regards to a lambda abstraction are known as \emph{free
  variables}~\cite{functional-Barendregt, lambda-Hindley, lambda-Church}. Bound
variables can be renamed without changing the behavior, it is known as
\emph{α-equivalence}~\cite{lambda-Revesz, type-Pierce, tt-Nederpelt}. For
example,
\begin{equation}
  (\lambda x.\ \lambda y.\ x\ (x\ y))\ (\lambda x.\ y\ x)
  \label{eq:lambda-ex}
\end{equation} is a
lambda term, which is α-equivalent to
\begin{equation}
  (\lambda a.\ \lambda b.\ a\ (a\ b))\ (\lambda c.\ y\ c)
  \label{eq:lambda-ex-rename}
\end{equation}
Note that the \(y\) here cannot be renamed, since it is a free variable, and
that the \(x\)s were bound to different binders, which is why they can become
both \(a\) and \(c\).

\begin{figure}
  \begin{alignat*}{2}
    t, u \Coleqq{} & x             & \qquad\text{variable}             \\
    \mid{}         & \lambda x.\ t & \qquad\text{lambda abstraction}   \\
    \mid{}         & t\ u          & \qquad\text{function application}
  \end{alignat*}
  \caption{The syntax of untyped lambda calculus}\label{fig:lambda-syntax}
\end{figure}

Lambda calculus has a single rule for computation known as
\emph{β-reduction}, the rule is as follows~\cite{functional-Hudak,
  lambda-Hindley, tt-Nederpelt}:
\begin{equation}
  (\lambda x.\ t)\ u \mapsto t[x \coleqq u]
  \label{eq:beta}
\end{equation}
One needs to be careful about variable names when substituting to avoid
accidental capture of free variables~\cite{functional-Hudak, lambda-Barendregt}.
For example, the lambda term in \cref{eq:lambda-ex} will become
\begin{equation}
  \lambda z.\ (\lambda x.\ y\ x)\ ((\lambda x.\ y\ x)\ z)
  \label{eq:lambda-ex-beta}
\end{equation}
after one β-reduction step. Note that the bound \(y\) is renamed to \(z\) to
avoid clashing with the free \(y\) variable.

Another concept is \emph{η-equivalence}, which says the
following~\cite{functional-Hudak, lambda-Barendregt}:
\begin{equation}
  (\lambda x.\ f\ x) \simeq f
\end{equation}
where \(x\) is not a free variable in \(f\). The two sides are equated since
they are equal after applying to an argument.

Lambda terms which can be β-reduced are known as \emph{reducible expression}
(\emph{redex}), terms which do not have a redex are said to be in \emph{normal
  form}~\cite{functional-Barendregt, lambda-Hindley, tt-Nederpelt}. At each step
there can be many ways to apply β-reduction, but according to the
Church{--}Rosser theorem, the normal forms after repeated reduction (if it
terminates) are always equivalent regardless of the order of β-reduction steps,
this property is \emph{confluence}~\cite{lambda-Hindley, churchrosser,
  tt-Nederpelt}.

Some lambda terms do not have normal forms at all, for
example~\cite{functional-Hudak, lambda-Hindley, type-Pierce}:
\begin{equation}
  \Omega = (\lambda x.\ x\ x)\ (\lambda x.\ x\ x)
  \label{eq:omega}
\end{equation}
General recursion can also be represented, for example with the \emph{Y
  combinator}~\cite{functional-Hudak, lambda-Hindley, tt-Nederpelt}:
\begin{equation}
  Y = \lambda f.\ (\lambda x.\ f\ (x\ x))\ (\lambda x.\ f\ (x\ x))
  \label{eq:ycomb}
\end{equation}
however, it is inefficient in practice, so programming languages do not
typically use it to implement recursion. One can show that the untyped lambda
calculus is Turing-complete~\cite{lambda-Turing, type-Pierce}.

\subsection{Evaluation strategies}\label{ssec:strat}

There are different strategies to select which β-reduction step to take.

Mainstream programming languages take the \emph{call-by-value} strategy, where
one first evaluates the argument before reducing a redex, however it can lead to
non-termination for some terms even though there is a sequence of reductions
which lead to a normal form~\cite{sicp, lambda-Sestoft, type-Pierce}.

Another strategy is \emph{call-by-name}, where one always reduces the leftmost
outermost redex. This will always produce a normal form where it exists, however
there can be redundant computations on identical terms~\cite{sicp,
  lambda-Sestoft}.

A compromise between the two strategies is \emph{call-by-need}, where function
arguments are memoized when needed, therefore they are evaluated at most once,
but untouched when not needed~\cite{functional-Hudak, callbyneed}, thought it
can lead to space leaks when arguments are unnecessarily stored in unevaluated
thunks~\cite{spaceleak}.

\subsection{Church encoding}\label{ssec:church}

For practical programming, data types can be encoded with purely lambda
functions. There is the \emph{Church encoding}, which encodes inductive data
types with their folds or recursor~\cite{church-Koopman, scott-Jansen}.

For example, a natural number can be represented by a function which takes a
function and a constant, then using the function as the successor function and
the constant as zero~\cite{lambda-Revesz, lambda-Church, type-Pierce}. The
number 5 can be represented as follows:
\begin{equation}
  \lambda f.\ \lambda x.\ f (f (f (f (f\ x))))
  \label{eq:lambda-church-ex}
\end{equation}

Operations which can be defined with folds, such as addition and multiplication,
can be defined simply on the Church-encoded numbers as well, however operations
such as the predecessor function has to be defined in a more complicated way and
its time complexity is \(O(n)\)~\cite{lambda-Revesz, type-Pierce}.

\emph{Scott encoding} avoids this problem by encoding recursive data types with
their destructors, however recursive operations need to be defined using general
recursion and recursive types are required to represent them in typed
settings~\cite{combinator-Curry, church-Koopman, scott-Jansen}. The two
encodings coincide for non-recursive data types.

\subsection{De Bruijn indices and de Bruijn levels}\label{ssec:debruijn}

One can use \emph{de Bruijn indices} or \emph{de Bruijn levels} to avoid
variable names and have trivial α-equivalence. Variables are represented by
numbers based on which accessible lambda abstraction they are bound to. De
Bruijn indices count from the innermost lambda abstraction, while de Bruijn
levels count from the outermost~\cite{debruijn}.

For example, with de Bruijn indices, the lambda term in \cref{eq:lambda-ex} can
be written as
\begin{equation}
  (\lambda\ \lambda\ 1\ (1\ 0))\ (\lambda\ 1\ 0)
  \label{eq:lambda-ex-index}
\end{equation}
Note that the free \(y\) variable becomes a number outside of the range of its
accessible lambda abstractions.

\section{Types}\label{sec:types}

To avoid non-termination and ill behaved terms, one can add types to lambda
calculus.

The simplest version of typed lambda calculus is the \emph{simply typed lambda
  calculus} (\caps{STLC})~\cite{type-Church}. Types which are separate from
terms are added to untyped lambda calculus. There are only two constructs, a
base type and function types (see \cref{fig:stlc-type-syntax}). Each lambda
abstraction binder is annotated with a type~\cite{type-Barendregt,
  type-Pierce}. For example, the \(\mathit{twice}\) function from
\cref{eq:higher-order-ex} can be written as follows:
\begin{equation}
  \lambda (f : \iota \to \iota).\ \lambda (x : \iota).\ f\ (f\ x)
  \label{eq:stlc-higher-order-ex}
\end{equation}

\begin{figure}
  \begin{alignat*}{2}
    A, B \Coleqq{} & \iota   & \qquad\text{base type} \\
    \mid{}         & A \to B & \qquad\text{function}
  \end{alignat*}
  \caption{The syntax of \caps{STLC} types}\label{fig:stlc-type-syntax}
\end{figure}

One can check if a term is correctly typed with the rules from
\cref{fig:stlc-typing}, and all correctly typed terms
terminate~\cite{type-Barendregt, type-Pierce}. Unfortunately \caps{STLC} is too
restrictive, as it does not allow parametric polymorphic functions, the function
in \cref{eq:stlc-higher-order-ex} needs to be repeated for every type one plans
to use it on.

\begin{figure}
  \begin{equation*}
    \begin{prooftree}
      \infer0{\Gamma,\ x : A \vdash x : A}
    \end{prooftree}
    \qquad
    \begin{prooftree}
      \hypo{\Gamma,\ x : A \vdash t : B}
      \infer1{\Gamma \vdash \lambda (x : A).\ t : A \to B}
    \end{prooftree}
    \qquad
    \begin{prooftree}
      \hypo{\Gamma \vdash t : A \to B}
      \hypo{\Gamma \vdash u : A}
      \infer2{\Gamma \vdash t\ u : B }
    \end{prooftree}
  \end{equation*}
  \caption{The typing rules of \caps{STLC}}\label{fig:stlc-typing}
\end{figure}

A more advanced version of typed lambda calculus with parametric polymorphism is
\emph{System~F}~\cite{type-Pierce, type-Girard, tt-Nederpelt}. It allows terms
to depend on types by introducing abstraction and application of types by terms
(see \cref{fig:systemf-typing}).

\begin{figure}
  \begin{equation*}
    \begin{prooftree}
      \hypo{\Gamma,\ X : \Univ \vdash t : A}
      \infer1{\Gamma \vdash \Lambda X.\ t : \forall X.\ A}
    \end{prooftree}
    \qquad
    \begin{prooftree}
      \hypo{\Gamma \vdash t : \forall X.\ A}
      \hypo{\Gamma \vdash B : \Univ}
      \infer2{\Gamma \vdash t\ B : A[X \mapsto B]}
    \end{prooftree}
  \end{equation*}
  \caption{The extra typing rules of System~F}\label{fig:systemf-typing}
\end{figure}

One can encode data types with Boehm{--}Berducci
encoding~\cite{boehmberarducci}, the typed version of Church encoding. For
example, the following type represents natural numbers:
\begin{equation}
  \forall X.\ (X \to X) \to (X \to X)
  \label{eq:stlc-church-type}
\end{equation}
Then the number 5 can be represented as follows:
\begin{equation}
  \Lambda X.\ \lambda (f : X \to X).\ \lambda (x : X).\ f (f (f (f (f\ x))))
  \label{eq:stlc-church-ex}
\end{equation}

There is a subset of System~F known as Hindley{--}Milner~\cite{milner}, where
all the types can be omitted and inferred automatically, the \caps{ML} family of
languages are based on it~\cite{haskell2010, ml}.

If one allows types to depend on terms and types (see \cref{fig:dep-typing}),
then one arrives at full dependent type theory. This erases the distinction
between terms and types, so term evaluation is necessary during type-checking as
well, but correctly typed terms still terminate~\cite{martinloef, coc,
tt-Nederpelt}. These previously mentioned systems are part of the lambda cube,
where you can get different type systems depending on whether types and terms
can depend on each other~\cite{tt-Nederpelt, lambdacube}.

\begin{figure}
  \begin{equation*}
    \begin{prooftree}
      \hypo{\Gamma,\ x : A \vdash t : B}
      \infer1{\Gamma \vdash \lambda x.\ t : \forall (x : A).\ B}
    \end{prooftree}
    \qquad
    \begin{prooftree}
      \hypo{\Gamma \vdash t : \forall (x : A).\ B}
      \hypo{\Gamma \vdash u : A}
      \infer2{\Gamma \vdash t\ u : B[x \mapsto u]}
    \end{prooftree}
  \end{equation*}
  \caption{The new typing rule for dependent types}\label{fig:dep-typing}
\end{figure}

Due to Curry{--}Howard correspondence, types can be seen as propositions in
intuitionistic logic and terms can be seen as proofs of those
propositions~\cite{prop-Wadler, curryhoward}. For example, the type
\begin{equation}
  (A → (B → C)) → ((A → B) → (A → C))
  \label{eq:curryhoward-type}
\end{equation}
can be seen as a proposition where the function arrows are implications, and the proof is the term
\begin{equation}
  \lambda (f : A → (B → C)).\ \lambda (g : A → B).\ \lambda (x : A).
  \ (f\ x)\ (g\ x)
  \label{eq:curryhoward-term}
\end{equation}
